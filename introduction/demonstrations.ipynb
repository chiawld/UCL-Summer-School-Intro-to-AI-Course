{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to AI Summer School! ü§ñ\n",
    "\n",
    "## What You'll Discover Today\n",
    "\n",
    "Welcome to your first hands-on experience with Artificial Intelligence! Whether you're already comfortable with programming or new to coding, this notebook will demonstrate some impressive AI applications that are shaping our world right now.\n",
    "\n",
    "**Don't worry about understanding every line of code** - the focus is on seeing AI in action and understanding its potential impact.\n",
    "\n",
    "### Today's AI Demonstrations:\n",
    "1. **Sentiment Analysis** - How computers interpret human emotions in text\n",
    "2. **Computer Vision** - Object detection and image analysis\n",
    "3. **Neural Style Transfer** - AI-powered artistic image transformation\n",
    "4. **Text Similarity** - Measuring semantic relationships between sentences\n",
    "5. **Current AI Tools** - Exploring today's most influential AI applications\n",
    "\n",
    "**Ready to explore?** Let's begin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running in Google Colab\n",
    "\n",
    "Google Colab provides free access to GPUs and has most AI libraries pre-installed, making it ideal for AI experimentation. Here's how to use this notebook effectively:\n",
    "\n",
    "### Getting Started:\n",
    "1. **Execute cells sequentially** - Click the play button (‚ñ∂Ô∏è) or use `Shift + Enter`\n",
    "2. **Wait for completion** - Let each cell finish before proceeding\n",
    "3. **Ignore warnings** - Most are informational and won't affect functionality\n",
    "4. **Experiment freely** - Feel free to modify parameters and try different inputs\n",
    "\n",
    "### Useful Tips:\n",
    "- **Runtime menu**: Use \"Restart and run all\" if you need a fresh start\n",
    "- **Save your work**: File ‚Üí Save a copy in Drive\n",
    "- **GPU acceleration**: Runtime ‚Üí Change runtime type ‚Üí GPU (if available)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up Our AI Environment\n",
    "\n",
    "Before we begin, we need to install and import the necessary AI libraries. These include:\n",
    "\n",
    "- **Transformers**: Pre-trained language models from Hugging Face\n",
    "- **TensorFlow**: Google's machine learning framework\n",
    "- **OpenCV & PIL**: Image processing libraries\n",
    "- **NumPy & Pandas**: Data manipulation tools\n",
    "- **Matplotlib**: Visualisation library\n",
    "\n",
    "The setup process involves two steps: installation and importing.\n",
    "\n",
    "### Installing Required Packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing AI libraries for Google Colab...\n",
      "This may take 2-3 minutes on first run.\n",
      "Installation complete. Ready to proceed.\n"
     ]
    }
   ],
   "source": [
    "# Install required packages for this notebook\n",
    "print(\"Installing AI libraries for Google Colab...\")\n",
    "print(\"This may take 2-3 minutes on first run.\")\n",
    "\n",
    "!pip install -q transformers torch tensorflow-hub opencv-python-headless\n",
    "!pip install -q --upgrade tensorflow\n",
    "\n",
    "print(\"Installation complete. Ready to proceed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in standard Jupyter environment\n",
      "Consider using Google Colab for optimal performance\n",
      "\n",
      "Environment setup complete\n"
     ]
    }
   ],
   "source": [
    "# Environment check - verify we're running in Google Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    print(\"Running in Google Colab environment\")\n",
    "    \n",
    "    import tensorflow as tf\n",
    "    # Check for GPU availability\n",
    "    if tf.config.list_physical_devices('GPU'):\n",
    "        print(\"GPU acceleration available\")\n",
    "    else:\n",
    "        print(\"Using CPU (still suitable for this demonstration)\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"Running in standard Jupyter environment\")\n",
    "    print(\"Consider using Google Colab for optimal performance\")\n",
    "\n",
    "print(\"\\nEnvironment setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Colab-specific image display\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpatches\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cv2_imshow\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll libraries imported successfully\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReady for AI demonstrations\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "# Import essential libraries\n",
    "import numpy as np              # Numerical computing\n",
    "import pandas as pd             # Data manipulation\n",
    "import matplotlib.pyplot as plt # Plotting and visualisation\n",
    "import requests                 # HTTP requests for image downloads\n",
    "from PIL import Image          # Image processing\n",
    "from io import BytesIO         # Binary I/O operations\n",
    "\n",
    "# Machine learning and AI libraries\n",
    "import tensorflow as tf        # Deep learning framework\n",
    "import tensorflow_hub as hub   # Pre-trained model repository\n",
    "import torch                   # PyTorch deep learning framework\n",
    "from transformers import pipeline, BertModel, BertTokenizer  # NLP models\n",
    "from sklearn.metrics.pairwise import cosine_similarity       # Similarity metrics\n",
    "\n",
    "# Colab-specific image display\n",
    "import cv2\n",
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "print(\"All libraries imported successfully\")\n",
    "print(\"Ready for AI demonstrations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Sentiment Analysis\n",
    "**Understanding Emotions in Text**\n",
    "\n",
    "Sentiment analysis is a fundamental NLP task that determines the emotional tone of text. It's widely used in business applications like customer feedback analysis, social media monitoring, and market research.\n",
    "\n",
    "We'll use a pre-trained model to analyse various text samples and observe its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading sentiment analysis model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c0eb58ba7284eb88f60444d5458892b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92eb4ef6f7a340c4a687a87ba3ceafae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ab36c476bad496691dac7d670331ce6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eeacbb3265b482095212b8fecc7a254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained sentiment analysis model\n",
    "print(\"Loading sentiment analysis model...\")\n",
    "sentiment_analysis = pipeline(\"sentiment-analysis\")\n",
    "print(\"Model loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample texts for analysis:\n",
      "1. I absolutely love this sunny weather!\n",
      "2. This traffic jam is incredibly frustrating\n",
      "3. The movie was okay, nothing special\n",
      "4. I'm feeling a bit down today\n",
      "5. This pizza is amazing!\n",
      "6. I can't believe my team won the championship!\n"
     ]
    }
   ],
   "source": [
    "# Sample texts with varying sentiment\n",
    "texts = [\n",
    "    \"I absolutely love this sunny weather!\",\n",
    "    \"This traffic jam is incredibly frustrating\",\n",
    "    \"The movie was okay, nothing special\",\n",
    "    \"I'm feeling a bit down today\",\n",
    "    \"This pizza is amazing!\",\n",
    "    \"I can't believe my team won the championship!\"\n",
    "]\n",
    "\n",
    "print(\"Sample texts for analysis:\")\n",
    "for i, text in enumerate(texts, 1):\n",
    "    print(f\"{i}. {text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Analysis Results:\n",
      "==================================================\n",
      "+ \"I absolutely love this sunny weather!\"\n",
      "   Prediction: POSITIVE (Confidence: 100.0%)\n",
      "----------------------------------------\n",
      "- \"This traffic jam is incredibly frustrating\"\n",
      "   Prediction: NEGATIVE (Confidence: 99.9%)\n",
      "----------------------------------------\n",
      "- \"The movie was okay, nothing special\"\n",
      "   Prediction: NEGATIVE (Confidence: 99.5%)\n",
      "----------------------------------------\n",
      "- \"I'm feeling a bit down today\"\n",
      "   Prediction: NEGATIVE (Confidence: 99.9%)\n",
      "----------------------------------------\n",
      "+ \"This pizza is amazing!\"\n",
      "   Prediction: POSITIVE (Confidence: 100.0%)\n",
      "----------------------------------------\n",
      "+ \"I can't believe my team won the championship!\"\n",
      "   Prediction: POSITIVE (Confidence: 99.9%)\n",
      "----------------------------------------\n",
      "+ \"I absolutely love this sunny weather!\"\n",
      "   Prediction: POSITIVE (Confidence: 100.0%)\n",
      "----------------------------------------\n",
      "- \"This traffic jam is incredibly frustrating\"\n",
      "   Prediction: NEGATIVE (Confidence: 99.9%)\n",
      "----------------------------------------\n",
      "- \"The movie was okay, nothing special\"\n",
      "   Prediction: NEGATIVE (Confidence: 99.5%)\n",
      "----------------------------------------\n",
      "- \"I'm feeling a bit down today\"\n",
      "   Prediction: NEGATIVE (Confidence: 99.9%)\n",
      "----------------------------------------\n",
      "+ \"This pizza is amazing!\"\n",
      "   Prediction: POSITIVE (Confidence: 100.0%)\n",
      "----------------------------------------\n",
      "+ \"I can't believe my team won the championship!\"\n",
      "   Prediction: POSITIVE (Confidence: 99.9%)\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Analyse sentiment for each text sample\n",
    "print(\"Sentiment Analysis Results:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "results = sentiment_analysis(texts)\n",
    "\n",
    "# Display results with confidence scores\n",
    "for text, result in zip(texts, results):\n",
    "    sentiment_icon = \"+\" if result['label'] == 'POSITIVE' else \"-\"\n",
    "    confidence = result['score'] * 100\n",
    "    \n",
    "    print(f\"{sentiment_icon} \\\"{text}\\\"\")\n",
    "    print(f\"   Prediction: {result['label']} (Confidence: {confidence:.1f}%)\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive testing - try your own text\n",
    "# Modify the text below to test different examples\n",
    "\n",
    "your_text = \"Replace this with your own message to test\"\n",
    "\n",
    "# Analyse your custom text\n",
    "your_result = sentiment_analysis([your_text])[0]\n",
    "sentiment_icon = \"+\" if your_result['label'] == 'POSITIVE' else \"-\"\n",
    "confidence = your_result['score'] * 100\n",
    "\n",
    "print(\"Your Custom Text Analysis:\")\n",
    "print(f\"{sentiment_icon} \\\"{your_text}\\\"\")\n",
    "print(f\"   Prediction: {your_result['label']} (Confidence: {confidence:.1f}%)\")\n",
    "print(\"\\nTry modifying the text above to test different phrases and expressions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1: Testing Model Limitations\n",
    "\n",
    "**Objective**: Explore edge cases where sentiment analysis might struggle.\n",
    "\n",
    "**Try these examples**:\n",
    "- Sarcastic statements: \"Oh great, another Monday...\"\n",
    "- Mixed emotions: \"I'm happy it's over but sad to leave\"\n",
    "- Context-dependent phrases: \"This is sick!\" (slang vs. literal)\n",
    "- Cultural references or idioms\n",
    "\n",
    "**Discussion points**:\n",
    "- How do confidence scores relate to your intuitive assessment?\n",
    "- What types of text seem to confuse the model?\n",
    "- How might training data bias affect results? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Computer Vision - Object Detection\n",
    "**Automated Visual Recognition**\n",
    "\n",
    "Object detection is a computer vision task that identifies and locates objects within images. This technology powers applications like autonomous vehicles, security systems, and photo organisation tools.\n",
    "\n",
    "We'll use a pre-trained model to analyse images and identify detected objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function for downloading and displaying images\n",
    "def display_image(url, title=\"Image\"):\n",
    "    try:\n",
    "        print(f\"Downloading image from: {url}\")\n",
    "        response = requests.get(url)\n",
    "        img = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "        \n",
    "        # Display the image\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.imshow(img)\n",
    "        plt.title(title, fontsize=14)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"Image loaded - Size: {img.size}\")\n",
    "        return img, np.array(img)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image: {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained object detection model\n",
    "print(\"Loading object detection model...\")\n",
    "print(\"This model was trained on the COCO dataset with 80+ object categories\")\n",
    "detector = hub.load(\"https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2\")\n",
    "print(\"Model loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select test image - urban street scene\n",
    "image_url = \"https://images.unsplash.com/photo-1449824913935-59a10b8d2000?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=1000&q=80\"\n",
    "\n",
    "print(\"Test image: Urban street scene\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display the test image\n",
    "img, imgarray = display_image(image_url, \"Original Image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare image for model input\n",
    "print(\"Preprocessing image for analysis...\")\n",
    "img = img.resize((640, 480))  # Resize to model's expected input size\n",
    "img_tensor = tf.convert_to_tensor(np.array(img), dtype=tf.uint8)\n",
    "img_tensor = tf.expand_dims(img_tensor, axis=0)  # Add batch dimension\n",
    "print(\"Image preprocessing complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run object detection inference\n",
    "print(\"Running object detection...\")\n",
    "print(\"Identifying objects and their locations...\")\n",
    "result = detector(img_tensor)\n",
    "print(\"Detection complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to draw bounding boxes on the image\n",
    "def draw_boxes(image, boxes, class_names, scores, max_boxes=10, min_score=0.5):\n",
    "    colors = list(plt.cm.tab20(np.linspace(0, 1, 20)))\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    for i in range(min(max_boxes, boxes.shape[0])):\n",
    "        if scores[i] >= min_score:\n",
    "            color = colors[int(class_names[i]) % len(colors)]\n",
    "            ymin, xmin, ymax, xmax = tuple(boxes[i])\n",
    "            image = cv2.rectangle(image, (int(xmin * img.width), int(ymin * img.height)),\n",
    "                                  (int(xmax * img.width), int(ymax * img.height)), color, 2)\n",
    "            image = cv2.putText(image, str(int(class_names[i])), (int(xmin * img.width), int(ymin * img.height) - 10),\n",
    "                                font, 0.5, color, 2)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract detection results\n",
    "boxes = result[\"detection_boxes\"][0].numpy()\n",
    "class_names = result[\"detection_classes\"][0].numpy()\n",
    "scores = result[\"detection_scores\"][0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw bounding boxes on the image\n",
    "output_img = draw_boxes(np.array(img), boxes, class_names, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display detection results\n",
    "print(\"Object Detection Results:\")\n",
    "\n",
    "# Use cv2_imshow for Colab compatibility\n",
    "cv2_imshow(output_img)\n",
    "\n",
    "# Also display with matplotlib\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(cv2.cvtColor(output_img, cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"Detected Objects with Bounding Boxes\", fontsize=16)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print(\"Each coloured box represents a detected object with its class ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2: Model Robustness Testing\n",
    "\n",
    "**Objective**: Test the object detection model with challenging scenarios.\n",
    "\n",
    "**Suggested test cases**:\n",
    "- Crowded scenes with overlapping objects\n",
    "- Unusual viewing angles or lighting conditions  \n",
    "- Abstract or artistic images\n",
    "- Very small or very large scale objects\n",
    "- Partially occluded objects\n",
    "\n",
    "**Image search suggestions**:\n",
    "- \"crowded marketplace\"\n",
    "- \"abstract geometric art\"\n",
    "- \"extreme close-up photography\"\n",
    "- \"low light photography\"\n",
    "\n",
    "**Analysis questions**:\n",
    "- What object categories does the model handle well/poorly?\n",
    "- How does object size affect detection accuracy?\n",
    "- What are the implications for real-world applications like autonomous vehicles? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Neural Style Transfer\n",
    "**Artistic Image Transformation**\n",
    "\n",
    "Neural style transfer combines the content of one image with the artistic style of another using deep neural networks. This technique demonstrates how AI can learn and apply artistic patterns, with applications in creative industries and image processing.\n",
    "\n",
    "Let's explore this fascinating intersection of art and technology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load AI artist model\n",
    "print(\"üé® Loading AI art studio...\")\n",
    "print(\"   This AI learned from thousands of famous paintings!\")\n",
    "style_transfer_model = hub.load(\"https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2\")\n",
    "print(\"‚úÖ AI artist ready to create masterpieces!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose our content image (what we want to paint) and style image (how we want to paint it)\n",
    "content_image_url = \"https://images.unsplash.com/photo-1535930891776-0c2dfb7fda1a?ixlib=rb-4.0.3&auto=format&fit=crop&w=400&q=80\"\n",
    "style_image_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/e/ea/Van_Gogh_-_Starry_Night_-_Google_Art_Project.jpg/400px-Van_Gogh_-_Starry_Night_-_Google_Art_Project.jpg\"\n",
    "\n",
    "print(\"üñºÔ∏è  Content Image: A beautiful landscape\")\n",
    "print(\"üé® Style Image: Van Gogh's 'Starry Night'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see our source images\n",
    "print(\"üì∑ CONTENT IMAGE (what to paint):\")\n",
    "content_img, content_array = display_image(content_image_url, \"Content Image\")\n",
    "\n",
    "print(\"\\nüé® STYLE IMAGE (how to paint it):\")\n",
    "style_img, style_array = display_image(style_image_url, \"Style Image - Van Gogh's Starry Night\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare both images for the AI artist\n",
    "print(\"üîß Preparing images for AI art creation...\")\n",
    "\n",
    "# Process content image\n",
    "content_image = tf.convert_to_tensor(content_array, dtype=tf.float32)\n",
    "content_image = tf.image.resize(content_image, (256, 256)) / 255.0\n",
    "content_image = tf.expand_dims(content_image, axis=0)\n",
    "                               \n",
    "# Process style image  \n",
    "style_image = tf.convert_to_tensor(style_array, dtype=tf.float32)\n",
    "style_image = tf.image.resize(style_image, (256, 256)) / 255.0\n",
    "style_image = tf.expand_dims(style_image, axis=0)\n",
    "\n",
    "print(\"‚úÖ Images ready for artistic transformation!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üé® The magic happens here! AI creates art!\n",
    "print(\"ü§ñ AI is painting... combining content with Van Gogh's style...\")\n",
    "stylized_image = style_transfer_model(tf.constant(content_image), tf.constant(style_image))[0]\n",
    "print(\"‚úÖ Masterpiece created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üñºÔ∏è Reveal the AI artwork!\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(stylized_image[0])\n",
    "plt.title('üé® AI-Generated Artwork\\n(Original photo painted in Van Gogh style!)', fontsize=16)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print(\"üéâ Amazing! The AI combined your photo with Van Gogh's painting style!\")\n",
    "print(\"üí° Try different images and see what the AI creates!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéÆ Challenge 3: Become an AI Art Critic!\n",
    "\n",
    "**Your Mission**: Test the style transfer with different combinations and rate the results!\n",
    "\n",
    "**Experiment with**:\n",
    "- Different artistic styles (Picasso, Monet, modern art)\n",
    "- Various content images (portraits, landscapes, architecture)  \n",
    "- Unusual combinations (cartoon + classical art, etc.)\n",
    "\n",
    "**Alternative Models to Try**:\n",
    "- üîó **TensorFlow Style Transfer Tutorial**: https://www.tensorflow.org/tutorials/generative/style_transfer\n",
    "- üîó **PyTorch Neural Style Tutorial**: https://pytorch.org/tutorials/advanced/neural_style_tutorial.html\n",
    "\n",
    "**Questions to explore**:\n",
    "- Which style-content combinations work best?\n",
    "- What makes a \"successful\" style transfer?\n",
    "- How does this compare to human artists?\n",
    "- Could this help or hurt human creativity? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Semantic Text Similarity\n",
    "**Measuring Meaning in Language**\n",
    "\n",
    "Semantic similarity measures how closely related two pieces of text are in meaning, beyond simple word matching. This technology is fundamental to search engines, recommendation systems, and natural language understanding applications.\n",
    "\n",
    "We'll use BERT embeddings to compute similarity scores between sentence pairs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BERT model for semantic similarity\n",
    "print(\"Loading BERT language model...\")\n",
    "print(\"BERT (Bidirectional Encoder Representations from Transformers)\")\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "print(\"BERT model loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_embedding(sentence):\n",
    "    # Tokenize the input sentence\n",
    "    inputs = tokenizer(sentence, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "    # Get the hidden states from the model\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    # Take the mean of the token embeddings from the last hidden state\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "    return embeddings.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity(sentence1, sentence2):\n",
    "    # Get sentence embeddings for both sentences\n",
    "    embedding1 = get_sentence_embedding(sentence1)\n",
    "    embedding2 = get_sentence_embedding(sentence2)\n",
    "    # Compute cosine similarity between the embeddings\n",
    "    similarity = cosine_similarity(embedding1, embedding2)[0][0]\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different sentence pairs to see how similar they are\n",
    "sentence_pairs = [\n",
    "    (\"AI is transforming the world.\", \"Artificial intelligence is changing everything.\"),\n",
    "    (\"The cat is sleeping peacefully.\", \"A feline is napping quietly.\"),\n",
    "    (\"I love pizza!\", \"Pizza is terrible.\"),\n",
    "    (\"The weather is sunny today.\", \"Today is a bright, clear day.\"),\n",
    "    (\"Programming is fun!\", \"I hate vegetables.\")\n",
    "]\n",
    "\n",
    "print(\"üîç Testing these sentence pairs for similarity:\")\n",
    "for i, (s1, s2) in enumerate(sentence_pairs, 1):\n",
    "    print(f\"\\n{i}. Sentence A: '{s1}'\")\n",
    "    print(f\"   Sentence B: '{s2}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see how similar each pair is!\n",
    "print(\"\\nü§ñ AI Similarity Analysis Results:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i, (sentence1, sentence2) in enumerate(sentence_pairs, 1):\n",
    "    similarity_score = compute_similarity(sentence1, sentence2)\n",
    "    \n",
    "    # Add interpretation\n",
    "    if similarity_score > 0.8:\n",
    "        interpretation = \"Very Similar! üéØ\"\n",
    "    elif similarity_score > 0.6:\n",
    "        interpretation = \"Quite Similar üëç\"\n",
    "    elif similarity_score > 0.4:\n",
    "        interpretation = \"Somewhat Similar ü§î\"\n",
    "    else:\n",
    "        interpretation = \"Not Very Similar üö´\"\n",
    "    \n",
    "    print(f\"\\n{i}. Pair {i}:\")\n",
    "    print(f\"   A: '{sentence1}'\")\n",
    "    print(f\"   B: '{sentence2}'\")\n",
    "    print(f\"   Similarity: {similarity_score:.3f} - {interpretation}\")\n",
    "\n",
    "print(\"\\nüí° 1.0 means identical, 0.0 means completely different!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéÆ YOUR TURN! Test your own sentences\n",
    "# Try to find two sentences that seem similar to you but confuse the AI\n",
    "\n",
    "your_sentence1 = \"Change this to your first sentence\"\n",
    "your_sentence2 = \"Change this to your second sentence\"\n",
    "\n",
    "your_similarity = compute_similarity(your_sentence1, your_sentence2)\n",
    "\n",
    "if your_similarity > 0.8:\n",
    "    interpretation = \"Very Similar! üéØ\"\n",
    "elif your_similarity > 0.6:\n",
    "    interpretation = \"Quite Similar üëç\"\n",
    "elif your_similarity > 0.4:\n",
    "    interpretation = \"Somewhat Similar ü§î\"\n",
    "else:\n",
    "    interpretation = \"Not Very Similar üö´\"\n",
    "\n",
    "print(\"üîç Your Sentence Similarity Test:\")\n",
    "print(f\"Sentence 1: '{your_sentence1}'\")\n",
    "print(f\"Sentence 2: '{your_sentence2}'\")\n",
    "print(f\"AI Similarity Score: {your_similarity:.3f} - {interpretation}\")\n",
    "print(\"\\nüèÜ Challenge: Can you get a score of exactly 0.500?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéÆ Challenge 4: The Similarity Score Olympics!\n",
    "\n",
    "**Your Mission**: Test the AI's understanding of language similarity!\n",
    "\n",
    "**Challenges to try**:\n",
    "1. **The Perfect Match**: Can you find two different sentences that get a similarity score of exactly 0.900?\n",
    "2. **The Synonym Test**: Do synonyms always get high scores? Test \"big\" vs \"large\", \"happy\" vs \"joyful\"\n",
    "3. **The Translation Test**: Compare \"Hello\" with \"Hola\" (or other languages you know)\n",
    "4. **The Context Test**: Do sentences with the same words but different meanings confuse the AI?\n",
    "\n",
    "**Examples to explore**:\n",
    "- \"The bank was closed\" vs \"The river bank was muddy\"\n",
    "- \"Time flies like an arrow\" vs \"Fruit flies like a banana\"  \n",
    "- \"I saw her duck\" vs \"I saw her duck under the table\"\n",
    "\n",
    "**Discussion Points**:\n",
    "- When does the AI get similarity \"wrong\" in your opinion?\n",
    "- How might cultural context affect similarity scores?\n",
    "- What are the limitations of measuring meaning mathematically?\n",
    "\n",
    "### üèÜ **Leaderboard Challenge**: Who can achieve the highest similarity score between two completely different-looking sentences? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current AI Tools and Applications\n",
    "\n",
    "The AI landscape is rapidly evolving. Here are some notable current applications and tools that demonstrate the practical impact of AI technologies:\n",
    "\n",
    "### Image Generation and Computer Vision\n",
    "- **DALL-E 3** (OpenAI): Text-to-image generation ‚Üí https://openai.com/dall-e-3\n",
    "- **Midjourney**: AI art generation platform ‚Üí https://midjourney.com\n",
    "- **Stable Diffusion**: Open-source image generation ‚Üí https://stablediffusionweb.com\n",
    "\n",
    "### Natural Language Processing\n",
    "- **ChatGPT**: Conversational AI system ‚Üí https://chatgpt.com\n",
    "- **Claude**: AI assistant by Anthropic ‚Üí https://claude.ai\n",
    "- **Perplexity**: AI-enhanced search engine ‚Üí https://perplexity.ai\n",
    "\n",
    "### Audio and Media Processing\n",
    "- **Suno**: AI music generation ‚Üí https://suno.com\n",
    "- **ElevenLabs**: Voice synthesis and cloning ‚Üí https://elevenlabs.io\n",
    "- **RunwayML**: AI-powered video editing ‚Üí https://runwayml.com\n",
    "\n",
    "### Development Tools\n",
    "- **GitHub Copilot**: AI code completion\n",
    "- **Codeium**: AI programming assistant\n",
    "- Many of these tools can be integrated with or run alongside Google Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration Activities\n",
    "\n",
    "**Practical exercises to deepen understanding**:\n",
    "\n",
    "1. **Prompt Engineering**: Experiment with different text inputs for AI image generators\n",
    "2. **Comparative Analysis**: Test the same prompt across different AI chat systems\n",
    "3. **Technical Investigation**: Use ChatGPT or similar tools to explain code snippets from this notebook\n",
    "4. **Creative Applications**: Generate content (music, images, text) and analyse the results\n",
    "\n",
    "### Discussion Topics\n",
    "\n",
    "Consider these questions as you explore AI applications:\n",
    "- Which demonstration was most impressive from a technical standpoint?\n",
    "- What are the potential societal implications of these technologies?\n",
    "- How might AI development affect different industries and professions?\n",
    "- What ethical considerations should guide AI development and deployment?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Course Overview\n",
    "\n",
    "This introductory session provides a foundation for the following topics:\n",
    "\n",
    "- **Day 2**: Python programming fundamentals and data preprocessing\n",
    "- **Day 3**: Supervised machine learning algorithms and evaluation\n",
    "- **Day 4**: Unsupervised learning techniques and pattern discovery  \n",
    "- **Day 5**: Neural networks and deep learning architectures\n",
    "- **Day 6**: Natural language processing and text analysis\n",
    "- **Day 8**: Reinforcement learning and decision-making systems\n",
    "- **Day 10**: Modern AI frameworks and implementation tools\n",
    "\n",
    "### Saving and Sharing Your Work\n",
    "\n",
    "**Google Colab Options**:\n",
    "- Save to Google Drive: File ‚Üí Save a copy in Drive\n",
    "- Share with others: File ‚Üí Share (similar to Google Docs)\n",
    "- Export notebook: File ‚Üí Download ‚Üí Download .ipynb\n",
    "\n",
    "### Summary\n",
    "\n",
    "Today's demonstrations showcased several core AI capabilities that are transforming multiple industries. You've seen practical implementations of sentiment analysis, computer vision, neural style transfer, and semantic similarity measurement.\n",
    "\n",
    "These technologies represent just a fraction of current AI capabilities. As we progress through the course, you'll gain deeper understanding of the underlying principles and learn to implement similar systems yourself.\n",
    "\n",
    "**The field of AI continues to evolve rapidly - you're now equipped to explore and understand these developments.** "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sc2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
